# 통계

- 관찰(수집)된 자료(현상/상태)에 대해서 통계적(수치적)으로 처리하고 연구
- 기술통계와 추론통계가 있다



## 기술통계

- 기초통계를 이용해서 자료의 성질(특성)을 확인(설명)하는 것
- 대용량 빅데이터에 접근하는 방법은 통계를 활용하는것
- 세세한 정보는 그다지 중요하지 않다
- 자료의 커다란 특성을 확인 가능



- 통계적 수치 (통계량)

  - 중심에 대한 통계 (교재 2.1 데이터 중심의 지표)

  - 산포에 대한 통계 (교재 2.2 데이터의 산포도 지표)

  - 관계에 대한 통계 (교재 3.1 두 데이터 사이의 관계를 나타내는 지표)

  - 형태에 대한 통계



### 중심에 대한 통계

- 자료의 중심에 대한 경향을 나타냄
- 평균 :  자료에 대한 평균 (모평균 / 표본평균 / 샘플평균)
- 중앙값 : 자료의 50%에 해당하는 값
  - ㄴ자료를 정렬할 때, 가운데 오는 값
- 최빈값 : 가장 많이 등장하는 값



#### 평균 구하기

- ```python
  scores = np.array( df['english'][:10] )
  scores 
  array([42, 69, 56, 41, 57, 48, 65, 49, 65, 58])
  
  sum(scores) / len(scores) # 합계를 갯수만큼 나누기
  np.mean( scores ) # mean 사용하기
  df['english'][:10].mean()
  ```



#### 중앙값 구하기

- ```python
  sort_scores = np.sort( scores )
  sort_scores
  array([41, 42, 48, 49, 56, 57, 58, 65, 65, 69])
  
  size = len(sort_scores)
  if size % 2 == 0:
    m0 = sort_scores[size//2 - 1]
    m1 = sort_scores[size//2]
    mid = (m0 + m1) / 2
  else:
    mid = sort_scores[(size+1)//2-1]
  
  
  np.median(scores)  # median 사용하기
  df['english'][:10].median()
  ```



#### 최빈값 구하기

- ```python
  # 넘파이에는 최빈값을 구하는 함수가 없다
  pd.Series(scores).mode()
  0    65
  dtype: int64
      
  df['english'][:10].mode()
  0    65
  dtype: int64
  ```





### 산포에 대한 통계

- 자료의 변동성을 나타내는 수치
- 자료들이 중심으로부터 얼마나 멀리 떨어져 있는지를 나타냄
  1. 편차(deviation) : 관측(수집)값과 평균의 차이
  2. 변동(variation) : 편차의 제곱합
  3. 분산(variance) : 변동을 데이터의 수로 나눈 값
  4. 표준편차(Standard Deviation) : 분산의 제곱근



#### 편차 구하기

- ```python
  mean = np.mean(scores)
  
  # 관측(수집)값과 평균의 차이
  deviation = mean - scores
  deviation
  array([ 13., -14.,  -1.,  14.,  -2.,   7., -10.,   6., -10.,  -3.])
  ```



#### 변동 구하기

- ```python
  variation = np.sum(deviation**2)
  variation
  860.0
  ```



#### 분산 구하기

- ```python
  # 표본분산 (NumPy에 기본으로 설정됨)
  variation / len(scores)
  86.0
  np.var(scores)
  86.0
  
  # 불편분산 (Pandas에 설정되어 있음)
  variation / (len[scores] - 1)
  95.555555556
  df['english'][:10].var()
  95.555555556
  ```



#### 표준편차 구하기

- ```python
  np.std(scores)
  9.273618495495704
  
  df['english'][:10].std()
  9.273618495495704
  
  # Pandas는 이러한 통계량을 한 번에 계산
  df['english'][:10].describe()
  count    10.000000
  mean     55.000000
  std       9.775252
  min      41.000000
  25%      48.250000
  50%      56.500000
  75%      63.250000
  max      69.000000
  Name: english, dtype: float64
  ```



### 표준화와 편차

- 데이터에서 평균을 빼고 표준편차로 나누는 작업

  - 자료들이 서로 다른 분포를 가지고 있다면, 비교 작업이 어렵다
  - 자료들이 정규분포임을 가정
  - 평균, 분산에 상관 없이 표준화된 지표를 얻을 수 있다.

- 최소,최대,Robust, ...

- ```python
  z = (scores - mean) / np.std(scores)
  z
  array([-1.40182605,  1.50965882,  0.10783277, -1.50965882,  0.21566555,
         -0.75482941,  1.07832773, -0.64699664,  1.07832773,  0.32349832])
  ```

- 평균이 0이고 표준편차는 1이 된다.

- ```python
  np.mean(z), np.std(z)
  (-1.6653345369377347e-17, 0.9999999999999999)
  ```

- 편차값

  - 평균이50, 표준편차가 10이 되도록 정규화
  - 편차값이 50이면 평균적인 결과
  - 50보다 클 수록 상위 결과라는 의미로 해석

- ```python
  z = 50 + 10 * (scores - mean) / np.std(scores)
  z
  array([35.98173948, 65.09658825, 51.07832773, 34.90341175, 52.15665546,
         42.45170588, 60.78327732, 43.53003361, 60.78327732, 53.2349832 ])
  ```



### 관계에 대한 통계

- 자료와 자료간의 관계를 나타내는 수치
- 수치일 뿐, 실제 관계를 수치만 가지고 정확하게 표현할 수 없다.



#### 상관관계

- 공분산(Co-variance)
- 두 변수 사이의 분산
  - 두 변수의 분산이 같이 커지거나 작아지면 상관성이 있다고 해석
  - 혹은 그반대의 관계가 나타낼때도 상관성이 있다고 해석
- cov(x,y)=∑(x−x¯)(y−y¯) / (n−1)



- 공분산의 해석
  - cov > 0 : x가 큰값(작은값)을 가질 때, y도 큰값(작은값)을 가짐
    - x의 분산이 커질 때 , y의 분산도 커지는 경우
    - x의 분산이 작아질 때 , y의 분산도 작아지는 경우
    - 즉, x와 y 사이에 양의 상관성이 있다
  - cov < 0 : x와 y가 반대인 경우
    - x의 분산이 작아질 때, y의 분산은 커짐
    - x의 분산이 커질 때, y의 분산은 작아짐
    - x와 y 사이에 음의 상관성이 있다
  - cov = 0 인 경우, 0에 가까운 경우
    - x의 분산과 상관없이 y가 존재하는 경우
    - 음수,양수가 섞이기 때문에 0에 가까운 값을 갖게됨
    - 두 변수는 상관성이 적다



- 단점
  - 상관성이 낮아도 수치가 크면, 공분산 값이 크게 나올 수 있음
  - 반대로 상관성이 높아도 수치가 낮으면, 공분산 값이 작게 나올 수 있음
  - 상관계수 : 공분산의 값을 -1과 1사이의 값으로 표준화 한 값
    - -1과 1에 가까울수록 상관성이 높다
    - 0에 가까울수록 상관성이 낮다



#### 인과관계

- 추론통계에서 확인하고자 하는 것이 인과성이 될 수 있다

- 어떤 자료가 다른 자료의 원인이 되는 경우

- 모든 변수가 원인이 될 수 있는 것은 아니다.

- ```python
  # 영어점수와 수학점수의 공분산
  en_scores = np.array(df['english'][:10])
  ma_scores = np.array(df['mathematics'][:10])
  
  cov = np.cov( en_scores, ma_scores, ddof=0 )
  cov
  array([[86.  , 62.8 ],
         [62.8 , 68.44]])  
  # 86과 68.44는 영어,수학의 분산 / 공분산은 62.8
  
  np.corrcoef( en_scores, ma_scores )
  array([[1.        , 0.81856923],
         [0.81856923, 1.        ]])
  
  df[['english', 'mathematics' ]].corr()
  			english	   mathematics
  english		 1.000000 	0.723741
  mathematics	 0.723741	 1.000000
  ```

- 두 변수의 상관성을 확인하기 좋은 시각화 pair_plot을 이용해볼 수 있다

- ```python
  sns.pairplot( df[['english', 'mathematics']])
  ```



### 형태에 대한 통계

- 자료의 분포나 왜곡된 형태
- 왜도(Skewness) : 편향, 중심을 기준으로 좌우의 데이터가 편향된 형태를 나타냄
- 첨도(Kurtosis) : 뾰족함의 정도



## 추론통계

- 표본을 통해서 모집단을 추론하는 과정
- 통계가 모집단의 모든 특징을 전부 설명할 수는 없다.
- 표본을 통해서 모집단의 평균을 추측(완벽히 설명x) 가능하다. 



## 모집단과 표본

- ```python
  scores = np.array(df['score'])
  scores[:10]
  array([76, 55, 80, 80, 74, 61, 81, 76, 23, 80])
  ```

- 복원추출과 비복원추출

- ```python
  np.random.choice(scores, 20)
  array([ 73,  96,  77,  73,  61,  74,  80,  46,  86,  63, 100,  64,  41,
          65,  81,  77,  76,  76,  67,  68])
  
  np.random.choice(scores, 20, replace = False)
  array([65, 71, 48, 85, 90, 62, 61, 57, 55, 84, 76, 87, 72, 46, 67, 60, 78,
         91, 42, 85])
  
  for i in range(5) :
      sample = np.random.choice(scores, 20)
      print('{}번째 무작위 추출 얻은 표본평균: {}'.format(i+1, sample.mean()))
  1번째 무작위 추출 얻은 표본평균: 74.3
  2번째 무작위 추출 얻은 표본평균: 69.6
  3번째 무작위 추출 얻은 표본평균: 65.95
  4번째 무작위 추출 얻은 표본평균: 69.0
  5번째 무작위 추출 얻은 표본평균: 70.15
      
  # 모집단의 평균
  scores.mean()
  69.53
  ```

- 























